<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <!-- iOS Safari -->
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <!-- Chrome, Firefox OS and Opera Status Bar Color -->
  <meta name="theme-color" content="#FFFFFF">
  <meta property="og:title" content="RepVGG 論文解讀，新的模型架構設計，CVPR 2021">
    <meta name="description" content="在現在深度學習模型越來越複雜的，或是各種NAS(neural architecture serach) 動輒幾千GPU小時找出的模型架構的時代，RegVGG 優雅的設計讓人眼睛一亮，提供大家未來設計模型的一個典範">
  <meta property="og:description" content="在現在深度學習模型越來越複雜的，或是各種NAS(neural architecture serach) 動輒幾千GPU小時找出的模型架構的時代，RegVGG 優雅的設計讓人眼睛一亮，提供大家未來設計模型的一個典範">
      <meta property="og:image" content="https://www.notion.so/images/page-cover/solid_beige.png">
    <meta property="og:type" content="blog">
  <title>RepVGG 論文解讀，新的模型架構設計，CVPR 2021</title>
  <!-- Favicon -->
    <link rel="shortcut icon" href="📖">
    <link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.11.1/katex.min.css">
  <link rel="stylesheet" type="text/css"
    href="https://cdnjs.cloudflare.com/ajax/libs/prism/1.19.0/themes/prism.min.css">
  <link rel="stylesheet" type="text/css" href="css/SourceSansPro.css">
  <link rel="stylesheet" type="text/css" href="css/notablog.css">
  <link rel="stylesheet" type="text/css" href="css/theme.css">
  <style>
    :root {
      font-size: 18px;
    }

    .DateTagBar {
      margin-top: 1.0rem;
    }
  </style>
  <!-- Global site tag (gtag.js) - Google Analytics -->
  <script async src="https://www.googletagmanager.com/gtag/js?id=G-WL5ZQD5CRE"></script>
  <script>
    window.dataLayer = window.dataLayer || [];
    function gtag(){dataLayer.push(arguments);}
    gtag('js', new Date());

    gtag('config', 'G-WL5ZQD5CRE');
  </script>
</head>

<body>
  <nav class="Navbar">
    <a href="index.html">
      <div class="Navbar__Btn"><span>📖</span> <span>Home</span></div>
    </a>
                                    <span class="Navbar__Delim">&centerdot;</span>
    <a href="about.html">
      <div class="Navbar__Btn"><span>😀</span> <span>About</span></div>
    </a>
                          </nav>
  <header class="Header">
          <div class="Header__Spacer Header__Spacer--NoCover">
    </div>
        <h1 class="Header__Title">RepVGG 論文解讀，新的模型架構設計，CVPR 2021</h1>
            <div class="DateTagBar">
                <span class="DateTagBar__Item DateTagBar__Date">Posted on Wed, Mar 24, 2021</span>
                          <span class="DateTagBar__Item DateTagBar__Tag DateTagBar__Tag--red">
            <a href="tag/deep learning.html">deep learning</a>
          </span>
                <span class="DateTagBar__Item DateTagBar__Tag DateTagBar__Tag--gray">
            <a href="tag/paper.html">paper</a>
          </span>
                <span class="DateTagBar__Item DateTagBar__Tag DateTagBar__Tag--purple">
            <a href="tag/CVPR.html">CVPR</a>
          </span>
                <span class="DateTagBar__Item DateTagBar__Tag DateTagBar__Tag--default">
            <a href="tag/model architecture.html">model architecture</a>
          </span>
                  </div>
          </header>
      <article id="https://www.notion.so/79fbfbd8d2884282b7ea7fdca7ddf9fc" class="PageRoot"><h1 id="https://www.notion.so/a30cbbaf05e44288befef729294cdf0d" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--1"><a class="Anchor" href="#https://www.notion.so/a30cbbaf05e44288befef729294cdf0d"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">簡介</span></span></h1><div id="https://www.notion.so/e5f3f6d3ba8a4bad9dcb09a89ff6f15e" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://www.blogger.com/blog/post/edit/447682606053420680/4060623792575238503#">RepVGG: Making VGG-style ConvNets Great Again</a></span><span class="SemanticString"> 將會收錄在 CVPR 2021，在現在深度學習模型越來越複雜的，或是各種NAS(neural architecture serach) 動輒幾千GPU小時找出的模型架構的時代中令人眼睛一亮的論文，在視覺相關任務的模型設計上可以提供很大的啟發。</span></span></p></div><div id="https://www.notion.so/0e09555713b948fa889fde594e5aa86d" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">建議讀者先有下列的知識，在閱讀此文章或論文時會好理解許多:</span></span></p></div><div id="https://www.notion.so/02253ca3d3994655a6ad83b5619d7ec6" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">1. 深度學習常見模型的架構: </span><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">VGG</strong></span><span class="SemanticString">、</span><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">ResNet</strong></span><span class="SemanticString">, Densenet, Inception 等，理解 CNN 模型演變史</span></span></p></div><div id="https://www.notion.so/ebbebbb807554e1aa73904cf3260bc40" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">2. 熟悉將 BN (batch norm) 的參數合併進 convolution 的方法。因 BN 和 convolution 實際上都是矩陣乘法和加法的運算，因此模型在推論 (inference) 時可以將 BN 合併進 convolution 來減少模型的參數和計算量，詳細的計算可以參考</span><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://www.blogger.com/blog/post/edit/447682606053420680/4060623792575238503#">這邊</a></span><span class="SemanticString">。</span></span></p></div><div id="https://www.notion.so/7dece510cc094a56b25b411d3396a266" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"></span></p></div><h1 id="https://www.notion.so/b190b0a195ca4dbf93babf1cbfca0a1f" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--1"><a class="Anchor" href="#https://www.notion.so/b190b0a195ca4dbf93babf1cbfca0a1f"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">背景</span></span></h1><div id="https://www.notion.so/647be10ba2fd41c88b3777d0a5b25aea" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">近年來深度學習模型的發展，多分支(multi-branch) 模型逐漸成為主流，例如 ResNet 的殘差連結(residual connect) 讓訓練較深的模型變容易，Inception 則藉由多分支來獲得不同感受野(receptive fileld)的特徵。多分支模型往往可以達到較高的效益，但也有一個很明顯地缺點: 記憶體使用量，多分支的模型比須保存中間結果直到分支合併，導致推論時速度變慢或是需要更多的記憶體，不利於工業界做模型的部署與加速。</span></span></p></div><div id="https://www.notion.so/9648717347c14765a5d41cf6b2e16b08" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">為了解決這個問題，作者設計了 RepVGG,  在多分支的狀況下訓練模型，並用結構重新參數化的方法將分支合併，讓模型在推論時只有單一分支，藉此達到高準確率又能維持記憶體使用量。</span></span></p></div><div id="https://www.notion.so/a8289719db864d778d96fffecbd9a2b2" class="Image Image--Normal"><figure><a href="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Ffce06e42-a916-450c-ad08-3457b08d6b79%2F.png?width=559&amp;table=block&amp;id=a8289719-db86-4d77-8d96-fffecbd9a2b2"><img src="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Ffce06e42-a916-450c-ad08-3457b08d6b79%2F.png?width=559&amp;table=block&amp;id=a8289719-db86-4d77-8d96-fffecbd9a2b2" style="width:559px"/></a><figcaption><span class="SemanticStringArray"><span class="SemanticString">                                          </span><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold">多分支的記憶體使用量較多示意圖</strong></span></span></figcaption></figure></div><div id="https://www.notion.so/4149e726e5a14824abec8ef74beae1d9" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"></span></p></div><h1 id="https://www.notion.so/09c528888f4e4fcface54ee58f5b64ea" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--1"><a class="Anchor" href="#https://www.notion.so/09c528888f4e4fcface54ee58f5b64ea"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">模型設計</span></span></h1><div id="https://www.notion.so/a66a36d0916c4587bd321d986b25c9c3" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">論文首先解釋為何模型骨架要使用 VGG，主要因為下列三個原因:</span></span></p></div><div id="https://www.notion.so/92ad78cea72a48a182f42da04b1692d4" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">1. 速度快: RepVGG 只使用 3*3 convolution ， NVIDIA cuDNN 或是 Intel MKL 都有對 3*3 convolution 做加速，而且未來如果某個硬體想對 RepVGG 的部署做優化，就只需要針對 3*3 convolution 的計算特別優化，不必考慮其他操作。</span></span></p></div><div id="https://www.notion.so/352a6fbf9c39450586cac6f038c8b23f" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">2. 節省記憶體: RepVGG 只有單一分支，不會遇到多分支模型需要保存中間結果導致記憶體使用量過大的麻煩。</span></span></p></div><div id="https://www.notion.so/253d93d6308248d283b91529d24a790f" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">3. 靈活有彈性: 多分支模型在做剪枝(pruning) 的時候會有許多限制，例如兩個需要合併的分支在做剪枝的時候必須移除相同的 channel ，導致許多剪枝的方法做在多分支模型上效果不佳。</span></span></p></div><div id="https://www.notion.so/6890e828ad6645cfab212916d0b25550" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">RepVGG 的模型其實很好理解，在原始 VGG 的架構中加入 1*1 的 convolution 分支和殘差分支，需要特別注意的地方是這些分支在合併前不會經過 relu ，讓 RepVGG 可以在訓練結束後將不同分支做合併。實驗結果也顯示多分支的效果顯著 ( 論文 Table. 4 )，RepVGG-A0 在不到 VGG16 十分之一的參數量下即可有相近的準確率，而 RepVGG-A2 則不論是準確率、速度和參數量都比 ResNet-50 優異。</span></span></p></div><div id="https://www.notion.so/c5da68e19e1c41838c007277cd1bd4cb" class="Image Image--Normal"><figure><a href="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fb22d5a34-5d27-48e1-9c26-b28184815f12%2Fregvgg_2.png?width=491&amp;table=block&amp;id=c5da68e1-9e1c-4183-8c00-7277cd1bd4cb"><img src="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2Fb22d5a34-5d27-48e1-9c26-b28184815f12%2Fregvgg_2.png?width=491&amp;table=block&amp;id=c5da68e1-9e1c-4183-8c00-7277cd1bd4cb" style="width:491px"/></a><figcaption><span class="SemanticStringArray"><span class="SemanticString">                                                  </span><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold"> RepVGG的模型設計     </strong></span><span class="SemanticString">           </span></span></figcaption></figure></div><div id="https://www.notion.so/6f38d170d84c4e8d9346536f652e4b69" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">分支的合併可以說是 RepVGG 的精隨，如下圖所示: 原本模型有 1 個 3*3 convolution </span><span class="SemanticString"><em class="SemanticString__Fragment SemanticString__Fragment--Italic">、</em></span><span class="SemanticString">1 個</span><span class="SemanticString"><em class="SemanticString__Fragment SemanticString__Fragment--Italic"> </em></span><span class="SemanticString">1</span><span class="SemanticString"><em class="SemanticString__Fragment SemanticString__Fragment--Italic">*</em></span><span class="SemanticString">1 的 convolution 和 1 個 identity 的殘差分支，首先 identity 可以視為 1</span><span class="SemanticString"><em class="SemanticString__Fragment SemanticString__Fragment--Italic">*</em></span><span class="SemanticString">1 </span><span class="SemanticString"><em class="SemanticString__Fragment SemanticString__Fragment--Italic">convolution </em></span><span class="SemanticString">的特例，因為只要 1*1 convolution 的 kernel 對應原始通道位置的權重等於 1，而其他通道位置的權重皆等於 0 ，就不會對輸入做任何的改變。而 11 的 convolution 又可以視為 33 的 convolution中的特例，也就是 kernel 只有中間非零，其餘八個位置的參數都是零的 33 convolution 。因此 RepVGG 可以視為有 3 個 3*3 convolution 分支。接下來將 BN 的參數合併到 33 convolution 的運算就跟本文開頭提到的部分一樣，而原本沒有 bias 的 convolution 在合併 BN 後會多了 bias 項 。最後將 3 個 3*3 convolution 的參數直接相加就得到 RepVGG 在推論階段時的模型參數。因此 RepVGG 可以在訓練時使用多分支來提高準確率，並且在推論可以只用一個3*3 convolution，達到高準確率又能有較低的記憶體使用量。</span></span></p></div><div id="https://www.notion.so/0f9f2c2d9ec84c8ebee144491fcfe931" class="Image Image--Normal"><figure><a href="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F5e1aa3ce-7e61-4e9a-b09b-e5d4394ab40a%2Fregvgg_3.png?width=598&amp;table=block&amp;id=0f9f2c2d-9ec8-4c8e-bee1-44491fcfe931"><img src="https://www.notion.so/signed/https%3A%2F%2Fs3-us-west-2.amazonaws.com%2Fsecure.notion-static.com%2F5e1aa3ce-7e61-4e9a-b09b-e5d4394ab40a%2Fregvgg_3.png?width=598&amp;table=block&amp;id=0f9f2c2d-9ec8-4c8e-bee1-44491fcfe931" style="width:598px"/></a><figcaption><span class="SemanticStringArray"><span class="SemanticString">                                                         </span><span class="SemanticString"><strong class="SemanticString__Fragment SemanticString__Fragment--Bold"> RegVGG 合併示意圖</strong></span></span></figcaption></figure></div><div id="https://www.notion.so/6fc87e7393424c929f9f0480f1c05614" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"></span></p></div><h1 id="https://www.notion.so/61ee29ce392b4c4b8a1b8534d04cad3a" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--1"><a class="Anchor" href="#https://www.notion.so/61ee29ce392b4c4b8a1b8534d04cad3a"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">實驗</span></span></h1><div id="https://www.notion.so/10f65f829c51401aa2dba7e029c3509d" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">實驗的部分就是展現 RepVGG 的快速和準確。比較有趣的是 ablation study 中的 +ReLU in branch ( 論文 Table. 7 ) 可以讓 RepVGG 得到更高的準確率，但加了 ReLU 這個非線性的操作後就無法將不同分支的 convolution 合併了。 這也是 ResNet 無法合併不同分支的主因，或許如何讓 ResNet 用類似的方法合併分支是不錯的研究方向，還可以結合模型剪枝在有分支的模型上的運用等相關問題....</span></span></p></div><div id="https://www.notion.so/40b839320d924d1a9a2d56e8ef2e40e9" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"></span></p></div><h1 id="https://www.notion.so/28900cab3b9c47d38755d16413fa5a79" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--1"><a class="Anchor" href="#https://www.notion.so/28900cab3b9c47d38755d16413fa5a79"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">結論</span></span></h1><div id="https://www.notion.so/e5255b0bd9344e5190a48c91c5518ae4" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">RepVGG 的模型架構簡潔有效，運用多分支的架構訓練模型來達到高準確率，再將模型轉變成單分支來降低記憶體使用量的想法值得效法，是一篇非常有價值的論文。</span></span></p></div><div id="https://www.notion.so/7b1123bdd90f42258e5c2f6e4220854d" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"></span></p></div><h1 id="https://www.notion.so/e10ac04ce01a4f5793d7b099374c09d2" class="ColorfulBlock ColorfulBlock--ColorDefault Heading Heading--1"><a class="Anchor" href="#https://www.notion.so/e10ac04ce01a4f5793d7b099374c09d2"><svg width="16" height="16" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a><span class="SemanticStringArray"><span class="SemanticString">延伸閱讀</span></span></h1><div id="https://www.notion.so/75681d2c6ae04abba488e1abda43b128" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">1. Winograd Convolution: 加速 3*3 convolution 的演算法，</span><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://www.blogger.com/blog/post/edit/447682606053420680/4060623792575238503#">開放課程</a></span><span class="SemanticString">有講解</span></span></p></div><div id="https://www.notion.so/602c19d0123848a68d835fd86f9dc83b" class="ColorfulBlock ColorfulBlock--ColorDefault Text"><p class="Text__Content"><span class="SemanticStringArray"><span class="SemanticString">2. ResNet 真的輸了嗎? 新的訓練 ResNet 的方法: </span><span class="SemanticString"><a class="SemanticString__Fragment SemanticString__Fragment--Link" href="https://www.blogger.com/blog/post/edit/447682606053420680/4060623792575238503#">Revisiting ResNets: Improved Training and Scaling Strategies</a></span></span></p></div></article>  <footer class="Footer">
        <div>&copy; Bomin's home 2019</div>
        <div>&centerdot;</div>
        <div>Powered by <a href="https://github.com/dragonman225/notablog" target="_blank"
            rel="noopener noreferrer">Notablog</a>.
        </div>
    </footer>
</body>

</html>